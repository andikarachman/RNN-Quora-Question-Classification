{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quora Questions Classification with Recurrent Neural Networks\n",
    "---\n",
    "\n",
    "<img src=\"assets/word_cloud.png\" width=60%>\n",
    "\n",
    "An existential problem for any major website today is how to handle toxic and divisive content. Quora wants to tackle this problem head-on to keep their platform a place where users can feel safe sharing their knowledge with the world.\n",
    "\n",
    "[Quora](https://www.quora.com) is a platform that empowers people to learn from each other. On Quora, people can ask questions and connect with others who contribute unique insights and quality answers. A key challenge is to weed out insincere questions -- those founded upon false premises, or that intend to make a statement rather than look for helpful answers.\n",
    "\n",
    "In this notebook, we will be predicting whether a question asked on Quora is sincere or not. An insincere question is defined as a question intended to make a statement rather than look for helpful answers. Some characteristics that can signify that a question is insincere:\n",
    "- Has a non-neutral tone\n",
    "  - Has an exaggerated tone to underscore a point about a group of people\n",
    "  - Is rhetorical and meant to imply a statement about a group of people\n",
    "- Is disparaging or inflammatory\n",
    "  - Suggests a discriminatory idea against a protected class of people, or seeks confirmation of a stereotype\n",
    "  - Makes disparaging attacks/insults against a specific person or group of people\n",
    "  - Based on an outlandish premise about a group of people\n",
    "  - Disparages against a characteristic that is not fixable and not measurable\n",
    "- Isn't grounded in reality\n",
    "  - Based on false information, or contains absurd assumptions\n",
    "- Uses sexual content (incest, bestiality, pedophilia) for shock value, and not to seek genuine answers\n",
    "\n",
    "The training data includes the question that was asked, and whether it was identified as insincere (target = 1). The ground-truth labels contain some amount of noise: they are not guaranteed to be perfect.\n",
    "\n",
    "Before moving to the next section, we need to import all packages required to do the analysis by calling the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data analysis packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Deep learning packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Miscellaneous\n",
    "import bcolz\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.0. Import the Data\n",
    "The data is acquired from [here](https://www.kaggle.com/c/quora-insincere-questions-classification/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "df = pd.read_csv('data/train.csv')\n",
    "df = df.iloc[0:1300000]\n",
    "\n",
    "# Show the first 5 rows the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only need data from `question_text` and `target` column. So, we put them in the `sentences` and `labels` variable, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = df['question_text']\n",
    "labels = df['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.0. Clean the Data\n",
    "To improve the predictive performance of the model, the following data cleaning are performed:\n",
    "- Lowercase all the words in the data\n",
    "- Remove short forms and mispellings\n",
    "- Ensure symbols and punctuations not to be attached to a certain word\n",
    "- Transform numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Lowercase All the Words\n",
    "We will make all words in our questions to be lowercases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lowercase all words\n",
    "sentences = sentences.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Remove Short Forms and Mispellings\n",
    "There are some short form words and mispellings in the dataset. We will fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionary of short form words and mispellings\n",
    "mispell_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \n",
    "                \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \n",
    "                \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n",
    "                \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \n",
    "                \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \n",
    "                \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \n",
    "                \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \n",
    "                \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \n",
    "                \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \n",
    "                \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \n",
    "                \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\n",
    "                \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \n",
    "                \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n",
    "                \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \n",
    "                \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \n",
    "                \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \n",
    "                \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \n",
    "                \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\n",
    "                \"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \n",
    "                \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \n",
    "                \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \n",
    "                \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \n",
    "                \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \n",
    "                \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \n",
    "                \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \n",
    "                \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \n",
    "                \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \n",
    "                \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \n",
    "                \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \n",
    "                \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \n",
    "                \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \n",
    "                \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \n",
    "                \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\n",
    "                \"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \n",
    "                \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \n",
    "                \"you're\": \"you are\", \"you've\": \"you have\", 'colour': 'color', 'centre': 'center', \n",
    "                'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', \n",
    "                'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor', \n",
    "                'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', \n",
    "                'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', \n",
    "                'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', \n",
    "                'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', \n",
    "                'theBest': 'the best', 'howdoes': 'how does', 'mastrubation': 'masturbation', \n",
    "                'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'vegina': 'vagina',\n",
    "                'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', \n",
    "                '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \n",
    "                \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', \n",
    "                'demonitization': 'demonetization', 'demonetisation': 'demonetization'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define `clean_mispell` function to fix short forms and mispellings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_mispell(text):\n",
    "    clean_text = text\n",
    "    for mispell in mispell_dict.keys():\n",
    "        if re.search(mispell, text):\n",
    "            clean_text = re.sub(mispell, mispell_dict[mispell], text)\n",
    "    return clean_text\n",
    "\n",
    "# remove short forms and mispellings\n",
    "sentences = sentences.apply(lambda x: clean_mispell(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Punctuations and Symbols\n",
    "Punctuations and symbols are often attached to a particular word. We define `clean_symbol` to ensure symbols and punctuations not to be attached to a certain word.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symbols = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', \n",
    "           ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', \n",
    "           '#', '*', '+', '\\\\', '•',  '~', '@', '£', '·', '_', \n",
    "           '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', \n",
    "           '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', \n",
    "           '½', 'à', '…', '“', '★', '”', '–', '●', 'â', '►', \n",
    "           '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', \n",
    "           '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', \n",
    "           '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', \n",
    "           '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', \n",
    "           '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', \n",
    "           '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', \n",
    "           '¹', '≤', '‡', '√', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_symbol(text):\n",
    "    text = str(text)\n",
    "    for symbol in symbols:\n",
    "        text = text.replace(symbol, f' {symbol} ')\n",
    "    return text\n",
    "\n",
    "# ensure symbols and punctuations not to be attached to a certain word\n",
    "sentences = sentences.apply(lambda x: clean_symbol(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Transform Numbers\n",
    "All number with more than 5 digits are transformed into '###'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_numbers(x):\n",
    "    x = re.sub('[0-9]{5,}', '###', x)\n",
    "    return x\n",
    "\n",
    "sentences = sentences.apply(lambda x: clean_numbers(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.0. Pre-process the Data\n",
    "We will implement the following pre-processing functions:\n",
    "- Tokenize the questions\n",
    "- Track vocabulary\n",
    "- Encode the data\n",
    "- Pad the questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Tokenize the Questions\n",
    "We will be splitting the questions into a word array using spaces as delimiters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenize all questions in the data\n",
    "sentences_token = sentences.apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length of questions is 71.\n",
      "Max word length of questions is 1017.\n",
      "Min word length of questions is 1.\n"
     ]
    }
   ],
   "source": [
    "print('Average word length of questions is {0:.0f}.'.format(np.mean(df['question_text'].apply(lambda x: len(x)))))\n",
    "print('Max word length of questions is {0:.0f}.'.format(np.max(df['question_text'].apply(lambda x: len(x)))))\n",
    "print('Min word length of questions is {0:.0f}.'.format(np.min(df['question_text'].apply(lambda x: len(x)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Track Vocabulary\n",
    "We define `track_vocab` to track our training vocabulary, which goes through all our text and counts the occurence of the contained words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def track_vocab(sentences, verbose =  True):\n",
    "    \n",
    "    vocab = {}\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "                \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'how': 289121, 'did': 44478, 'quebec': 167, 'nationalists': 151, 'see': 9668}\n"
     ]
    }
   ],
   "source": [
    "# count the occurrence of all words in the data\n",
    "vocab_count = track_vocab(sentences_token)\n",
    "print({k: vocab_count[k] for k in list(vocab_count)[:5]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Encode the Data\n",
    "Since we're using embedding layers, we'll need to encode each word with an integer. To create a word embedding, we first need to transform the words to ids.  In this function, we create two dictionaries:\n",
    "- Dictionary to go from the words to an id, we'll call `vocab_to_int`\n",
    "- Dictionary to go from the id to word, we'll call `int_to_vocab`\n",
    "\n",
    "We return these dictionaries in the **tuple** `(vocab_to_int, int_to_vocab)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_lookup_tables(vocab_count):\n",
    "    \n",
    "    # sorting the words from most to least frequent in text occurrence\n",
    "    sorted_vocab = sorted(vocab_count, key=vocab_count.get, reverse=True)\n",
    "    # create vocab_to_int dictionary\n",
    "    int_to_vocab = {ii: word for ii, word in enumerate(sorted_vocab)}\n",
    "    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
    "    \n",
    "    # return tuple\n",
    "    return (vocab_to_int, int_to_vocab)\n",
    "\n",
    "vocab_to_int, int_to_vocab = create_lookup_tables(vocab_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can convert our data into integers, so they can be passed into the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode the data\n",
    "sentence_ints = []\n",
    "for sentence in sentences_token:\n",
    "    sentence_ints.append([vocab_to_int[word] for word in sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Pad the Questions\n",
    "To deal with both short and very long question, we'll pad or truncate all our questions to a specific length. For questions shorter than some `seq_length`, we'll pad with 0s. For questions longer than `seq_length`, we can truncate them to the first `seq_length` words. A good `seq_length`, in this case, is 71, because the average question length from the data is 71.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_features(sentences_token, seq_length):\n",
    "    # getting the correct rows x cols shape\n",
    "    features = np.zeros((len(sentences_token), seq_length), dtype=int)\n",
    "\n",
    "    # for each review, I grab that review and \n",
    "    for i, row in enumerate(sentences_token):\n",
    "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
    "    \n",
    "    return features\n",
    "\n",
    "# pad the questions\n",
    "seq_length = 71\n",
    "features = pad_features(sentence_ints, seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.0. Define Training, Validation, and Test Set\n",
    "With our data in nice shape, we'll split it into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, val_test_X, train_y, val_test_y = train_test_split(features, labels, \n",
    "                                                            test_size=0.4, \n",
    "                                                            random_state=42, shuffle=True,\n",
    "                                                            stratify=labels)\n",
    "\n",
    "val_X, test_X, val_y, test_y = train_test_split(val_test_X, val_test_y, \n",
    "                                                test_size=0.5, \n",
    "                                                random_state=42, shuffle=True,\n",
    "                                                stratify=val_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoaders and Batching\n",
    "After creating training, test, and validation data, we can create DataLoaders for this data by following two steps:\n",
    "1. Create a known format for accessing our data, using [TensorDataset](https://pytorch.org/docs/stable/data.html#) which takes in an input set of data and a target set of data with the same first dimension, and creates a dataset.\n",
    "2. Create DataLoaders and batch our training, validation, and test Tensor datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_X), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_X), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_X), torch.from_numpy(test_y))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 50\n",
    "num_workers = 8\n",
    "\n",
    "# make sure to SHUFFLE the training data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, num_workers=num_workers)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([50, 71])\n",
      "Sample input: \n",
      " tensor([[    0,     0,     0,  ..., 28272,  1899,     0],\n",
      "        [    0,     0,     0,  ...,  1908,   316,     0],\n",
      "        [    0,     0,     0,  ...,   516,   222,     0],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ..., 18328,    25,     0],\n",
      "        [    0,     0,     0,  ...,    25,   113,     0],\n",
      "        [    0,     0,     0,  ...,    25,   123,     0]])\n",
      "\n",
      "Sample label size:  torch.Size([50])\n",
      "Sample label: \n",
      " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0])\n"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0. Build Network Architecture\n",
    "### 5.1. Import Pre-Trained Word Embeddings\n",
    "**Note**: This part is taken from a Medium article [How to use Pre-trained Word Embeddings in PyTorch](https://medium.com/@martinpella/how-to-use-pre-trained-word-embeddings-in-pytorch-71ca59249f76). \n",
    "\n",
    "Rather than training our own word vectors from scratch for word embedding, we will leverage on GloVe. Its authors have released four text files with word vectors trained on different massive web datasets. They are available for download [here](https://nlp.stanford.edu/projects/glove/). We will use “Wikipedia 2014 + Gigaword 5” which is the smallest file (“ [glove.6B.zip](http://nlp.stanford.edu/data/wordvecs/glove.6B.zip)”) with 822 MB. It was trained on a corpus of 6 billion tokens and contains a vocabulary of 400 thousand tokens.\n",
    "\n",
    "We need to parse the file to get as output: list of words, dictionary mapping each word to their id (position) and array of vectors. Given that the vocabulary have 400k tokens, we will use [bcolz](https://github.com/Blosc/bcolz) to store the array of vectors. It provides columnar, chunked data containers that can be compressed either in-memory and on-disk. It is based on NumPy, and uses it as the standard data container to communicate with bcolz objects. We then save the outputs to disk for future uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "idx = 0\n",
    "word2idx = {}\n",
    "vectors = bcolz.carray(np.zeros(1), rootdir=f'embedding/glove/6B.50.dat', mode='w')\n",
    "\n",
    "with open(f'embedding/glove/glove.6B.50d.txt', 'rb') as f:\n",
    "    for l in f:\n",
    "        line = l.decode().split()\n",
    "        word = line[0]\n",
    "        words.append(word)\n",
    "        word2idx[word] = idx\n",
    "        idx += 1\n",
    "        vect = np.array(line[1:]).astype(np.float)\n",
    "        vectors.append(vect)\n",
    "    \n",
    "vectors = bcolz.carray(vectors[1:].reshape((400000, 50)), rootdir=f'embedding/glove/6B.50.dat', mode='w')\n",
    "vectors.flush()\n",
    "pickle.dump(words, open(f'embedding/glove/6B.50_words.pkl', 'wb'))\n",
    "pickle.dump(word2idx, open(f'embedding/glove/6B.50_idx.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using those objects we can now create a dictionary that given a word returns its vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = bcolz.open(f'embedding/glove/6B.50.dat')[:]\n",
    "words = pickle.load(open(f'embedding/glove/6B.50_words.pkl', 'rb'))\n",
    "word2idx = pickle.load(open(f'embedding/glove/6B.50_idx.pkl', 'rb'))\n",
    "\n",
    "glove = {w: vectors[word2idx[w]] for w in words}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need to do at this point is to create an embedding layer, that is a dictionary mapping integer indices (that represent words) to dense vectors. It takes as input integers, it looks up these integers into an internal dictionary, and it returns the associated vectors.\n",
    "\n",
    "We have already built a Python dictionary with similar characteristics, but it does not support auto differentiation so can not be used as a neural network layer and was also built based on GloVe’s vocabulary, likely different from our dataset’s vocabulary. In PyTorch an embedding layer is available through torch.nn.Embedding class.\n",
    "\n",
    "We must build a matrix of weights that will be loaded into the PyTorch embedding layer. Its shape will be equal to (dataset’s vocabulary length, word vectors dimension).\n",
    "\n",
    "For each word in dataset’s vocabulary, we check if it is on GloVe’s vocabulary. If it do it, we load its pre-trained word vector. Otherwise, we initialize a random vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_vocab = sorted(vocab_count, key=vocab_count.get, reverse=True)\n",
    "target_vocab = sorted_vocab\n",
    "emb_dim = 50\n",
    "\n",
    "matrix_len = len(target_vocab)\n",
    "weights_matrix = np.zeros((matrix_len, 50))\n",
    "words_found = 0\n",
    "\n",
    "for i, word in enumerate(target_vocab):\n",
    "    try: \n",
    "        weights_matrix[i] = glove[word]\n",
    "        words_found += 1\n",
    "    except KeyError:\n",
    "        weights_matrix[i] = np.random.normal(scale=0.6, size=(emb_dim, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_emb_layer(weights_matrix, non_trainable=False):\n",
    "    num_embeddings, embedding_dim = weights_matrix.shape\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "\n",
    "    return emb_layer, num_embeddings, embedding_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Define RNN Architecture\n",
    "\n",
    "In this model, we use multiple bidirectional GRU/LSTM layers in the network. The bidirectional LSTM/GRU keeps the contextual information in both directions which is pretty useful in text classification task. \n",
    "\n",
    "We also use attention model to build our model architecture. In the past conventional methods like TFIDF/CountVectorizer etc., we used to find features from text by doing a keyword extraction. Some word are more helpful in determining the category of a text than others. But in this method we sort of lost the sequential structure of text. With LSTM and deep learning methods while we are able to take case of the sequence structure we lose the ability to give higher weightage to more important words. Attention mechanism is introduced to extract such words that are important to the meaning of the sentence and aggregate the representation of those informative words to form a sentence vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, training on CPU.\n"
     ]
    }
   ],
   "source": [
    "# First checking if GPU is available\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# implementation of attention layer\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        \n",
    "        self.supports_masking = True\n",
    "\n",
    "        self.bias = bias\n",
    "        self.feature_dim = feature_dim\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        \n",
    "        weight = torch.zeros(feature_dim, 1)\n",
    "        nn.init.kaiming_uniform_(weight)\n",
    "        self.weight = nn.Parameter(weight)\n",
    "        \n",
    "        if bias:\n",
    "            self.b = nn.Parameter(torch.zeros(step_dim))\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        feature_dim = self.feature_dim \n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = torch.mm(\n",
    "            x.contiguous().view(-1, feature_dim), \n",
    "            self.weight\n",
    "        ).view(-1, step_dim)\n",
    "        \n",
    "        if self.bias:\n",
    "            eij = eij + self.b\n",
    "            \n",
    "        eij = torch.tanh(eij)\n",
    "        a = torch.exp(eij)\n",
    "        \n",
    "        if mask is not None:\n",
    "            a = a * mask\n",
    "\n",
    "        a = a / (torch.sum(a, 1, keepdim=True) + 1e-10)\n",
    "\n",
    "        weighted_input = x * torch.unsqueeze(a, -1)\n",
    "        return torch.sum(weighted_input, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**First, we'll pass in words to an embedding layer.** We need an embedding layer because we have tens to hundreds of thousands of words, so we will need a more efficient representation for our input data than one-hot encoded vectors. \n",
    "\n",
    ">**After input words are passed to an embedding layer, the new embeddings will be passed to bidirectional LSTM/GRU layers.** These layers will add *recurrent* connections to the network and give us the ability to include information about the *sequence* of words in our data. The bidirectional LSTM/GRU layers keep the contextual information in both directions which is pretty useful in text classification task. \n",
    "\n",
    ">**The outputs of the bidirectional LSTM/GRU layers will be passed to the attention layer.** Attention mechanism is introduced to extract such words that are important to the meaning of the sentence and aggregate the representation of those informative words to form a sentence vector.\n",
    "\n",
    ">**Finally, the outputs will go to a output layer.** We are using a fully-connected neural network layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, weights_matrix, output_size, hidden_dim, drop_prob=0.3):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # embedding layers\n",
    "        self.embedding, self.num_embeddings, self.embedding_dim = create_emb_layer(weights_matrix, True)\n",
    "        \n",
    "        # embedding dropout\n",
    "        self.dropout = nn.Dropout2d(0.1)\n",
    "        \n",
    "        # lstm and GRU\n",
    "        self.lstm = nn.LSTM(self.embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.gru = nn.GRU(hidden_dim * 2, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        # attention layer\n",
    "        self.attention = Attention(hidden_dim*2, seq_length)\n",
    "        \n",
    "        # linear\n",
    "        self.fc = nn.Linear(hidden_dim*2, 64)\n",
    "        self.out = nn.Linear(64, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some inputs.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # embedding output\n",
    "        x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "        embeds = torch.squeeze(torch.unsqueeze(embeds, 0))\n",
    "        \n",
    "        # lstm, gru, and attention outputs\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        gru_out, _ = self.gru(lstm_out)\n",
    "        attention_out = self.attention(gru_out, 256)\n",
    "        \n",
    "        # linear outputs\n",
    "        fc_out = self.relu(self.fc(attention_out))\n",
    "        final_out = self.out(fc_out)\n",
    "        \n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(final_out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "    \n",
    "        return sig_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Instantiate the network\n",
    "Here, we'll instantiate the network. First up, defining the hyperparameters.\n",
    "\n",
    "* `weights_matrix`: The pre-trained word vector.\n",
    "* `output_size`: Size of our desired output.\n",
    "* `hidden_dim`: Number of units in the hidden layers of our LSTM cells. Usually larger is better performance wise. Common values are 128, 256, 512, etc.\n",
    "* `n_layers`: Number of LSTM layers in the network. Typically between 1-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (embedding): Embedding(194090, 50)\n",
      "  (dropout): Dropout2d(p=0.1)\n",
      "  (lstm): LSTM(50, 60, batch_first=True, bidirectional=True)\n",
      "  (gru): GRU(120, 60, batch_first=True, bidirectional=True)\n",
      "  (attention): Attention()\n",
      "  (fc): Linear(in_features=120, out_features=64, bias=True)\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "weights_matrix = weights_matrix\n",
    "output_size = 1\n",
    "hidden_dim = 60\n",
    "\n",
    "net = RNN(weights_matrix, output_size, hidden_dim)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4. Training\n",
    "We'll use a cross entropy loss, which is designed to work with a single Sigmoid output. [BCELoss](https://pytorch.org/docs/stable/nn.html#bceloss), or **Binary Cross Entropy Loss**, applies cross entropy loss to a single value between 0 and 1. We also have some data and training hyparameters:\n",
    "\n",
    "* `lr`: Learning rate for our optimizer.\n",
    "* `epochs`: Number of times to iterate through the training dataset.\n",
    "* `clip`: The maximum gradient value to clip at (to prevent exploding gradients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Step: 100... Loss: 0.180951... Val Loss: 0.228777\n",
      "Epoch: 1/1... Step: 200... Loss: 0.122095... Val Loss: 0.217856\n",
      "Epoch: 1/1... Step: 300... Loss: 0.246794... Val Loss: 0.193550\n",
      "Epoch: 1/1... Step: 400... Loss: 0.241540... Val Loss: 0.189776\n",
      "Epoch: 1/1... Step: 500... Loss: 0.237808... Val Loss: 0.181189\n",
      "Epoch: 1/1... Step: 600... Loss: 0.133767... Val Loss: 0.179677\n",
      "Epoch: 1/1... Step: 700... Loss: 0.193125... Val Loss: 0.175078\n",
      "Epoch: 1/1... Step: 800... Loss: 0.178750... Val Loss: 0.171360\n",
      "Epoch: 1/1... Step: 900... Loss: 0.201808... Val Loss: 0.169327\n",
      "Epoch: 1/1... Step: 1000... Loss: 0.079640... Val Loss: 0.167092\n",
      "Epoch: 1/1... Step: 1100... Loss: 0.069104... Val Loss: 0.163757\n",
      "Epoch: 1/1... Step: 1200... Loss: 0.063664... Val Loss: 0.168971\n",
      "Epoch: 1/1... Step: 1300... Loss: 0.099035... Val Loss: 0.162384\n",
      "Epoch: 1/1... Step: 1400... Loss: 0.062179... Val Loss: 0.160535\n",
      "Epoch: 1/1... Step: 1500... Loss: 0.129470... Val Loss: 0.157751\n",
      "Epoch: 1/1... Step: 1600... Loss: 0.190832... Val Loss: 0.160165\n",
      "Epoch: 1/1... Step: 1700... Loss: 0.036990... Val Loss: 0.154610\n",
      "Epoch: 1/1... Step: 1800... Loss: 0.182681... Val Loss: 0.154847\n",
      "Epoch: 1/1... Step: 1900... Loss: 0.108984... Val Loss: 0.151097\n",
      "Epoch: 1/1... Step: 2000... Loss: 0.216456... Val Loss: 0.151571\n",
      "Epoch: 1/1... Step: 2100... Loss: 0.245075... Val Loss: 0.151154\n",
      "Epoch: 1/1... Step: 2200... Loss: 0.201413... Val Loss: 0.152045\n",
      "Epoch: 1/1... Step: 2300... Loss: 0.055456... Val Loss: 0.147829\n",
      "Epoch: 1/1... Step: 2400... Loss: 0.078798... Val Loss: 0.151225\n",
      "Epoch: 1/1... Step: 2500... Loss: 0.111668... Val Loss: 0.148703\n",
      "Epoch: 1/1... Step: 2600... Loss: 0.067101... Val Loss: 0.148436\n",
      "Epoch: 1/1... Step: 2700... Loss: 0.078085... Val Loss: 0.145904\n",
      "Epoch: 1/1... Step: 2800... Loss: 0.142114... Val Loss: 0.146655\n",
      "Epoch: 1/1... Step: 2900... Loss: 0.092380... Val Loss: 0.147431\n",
      "Epoch: 1/1... Step: 3000... Loss: 0.212773... Val Loss: 0.145571\n",
      "Epoch: 1/1... Step: 3100... Loss: 0.251319... Val Loss: 0.146986\n",
      "Epoch: 1/1... Step: 3200... Loss: 0.073433... Val Loss: 0.144495\n",
      "Epoch: 1/1... Step: 3300... Loss: 0.126093... Val Loss: 0.154982\n",
      "Epoch: 1/1... Step: 3400... Loss: 0.252596... Val Loss: 0.142650\n",
      "Epoch: 1/1... Step: 3500... Loss: 0.388264... Val Loss: 0.141625\n",
      "Epoch: 1/1... Step: 3600... Loss: 0.117773... Val Loss: 0.141925\n",
      "Epoch: 1/1... Step: 3700... Loss: 0.123221... Val Loss: 0.144101\n",
      "Epoch: 1/1... Step: 3800... Loss: 0.038457... Val Loss: 0.140400\n",
      "Epoch: 1/1... Step: 3900... Loss: 0.112478... Val Loss: 0.144861\n",
      "Epoch: 1/1... Step: 4000... Loss: 0.068649... Val Loss: 0.142541\n",
      "Epoch: 1/1... Step: 4100... Loss: 0.102520... Val Loss: 0.140575\n",
      "Epoch: 1/1... Step: 4200... Loss: 0.349485... Val Loss: 0.141429\n",
      "Epoch: 1/1... Step: 4300... Loss: 0.227422... Val Loss: 0.139734\n",
      "Epoch: 1/1... Step: 4400... Loss: 0.141257... Val Loss: 0.139443\n",
      "Epoch: 1/1... Step: 4500... Loss: 0.081481... Val Loss: 0.139602\n",
      "Epoch: 1/1... Step: 4600... Loss: 0.167841... Val Loss: 0.142252\n",
      "Epoch: 1/1... Step: 4700... Loss: 0.288871... Val Loss: 0.139662\n",
      "Epoch: 1/1... Step: 4800... Loss: 0.063733... Val Loss: 0.139361\n",
      "Epoch: 1/1... Step: 4900... Loss: 0.077075... Val Loss: 0.138265\n",
      "Epoch: 1/1... Step: 5000... Loss: 0.065688... Val Loss: 0.137596\n",
      "Epoch: 1/1... Step: 5100... Loss: 0.074681... Val Loss: 0.137525\n",
      "Epoch: 1/1... Step: 5200... Loss: 0.106233... Val Loss: 0.137119\n",
      "Epoch: 1/1... Step: 5300... Loss: 0.132391... Val Loss: 0.138725\n",
      "Epoch: 1/1... Step: 5400... Loss: 0.107162... Val Loss: 0.137110\n",
      "Epoch: 1/1... Step: 5500... Loss: 0.302216... Val Loss: 0.136861\n",
      "Epoch: 1/1... Step: 5600... Loss: 0.174210... Val Loss: 0.137511\n",
      "Epoch: 1/1... Step: 5700... Loss: 0.183803... Val Loss: 0.142050\n",
      "Epoch: 1/1... Step: 5800... Loss: 0.171651... Val Loss: 0.137337\n",
      "Epoch: 1/1... Step: 5900... Loss: 0.025260... Val Loss: 0.134853\n",
      "Epoch: 1/1... Step: 6000... Loss: 0.228352... Val Loss: 0.135857\n",
      "Epoch: 1/1... Step: 6100... Loss: 0.085110... Val Loss: 0.135535\n",
      "Epoch: 1/1... Step: 6200... Loss: 0.060071... Val Loss: 0.135430\n",
      "Epoch: 1/1... Step: 6300... Loss: 0.114203... Val Loss: 0.135726\n",
      "Epoch: 1/1... Step: 6400... Loss: 0.131584... Val Loss: 0.138122\n",
      "Epoch: 1/1... Step: 6500... Loss: 0.137156... Val Loss: 0.135971\n",
      "Epoch: 1/1... Step: 6600... Loss: 0.035954... Val Loss: 0.134590\n",
      "Epoch: 1/1... Step: 6700... Loss: 0.195348... Val Loss: 0.133464\n",
      "Epoch: 1/1... Step: 6800... Loss: 0.057044... Val Loss: 0.133822\n",
      "Epoch: 1/1... Step: 6900... Loss: 0.269878... Val Loss: 0.134503\n",
      "Epoch: 1/1... Step: 7000... Loss: 0.259587... Val Loss: 0.135712\n",
      "Epoch: 1/1... Step: 7100... Loss: 0.131616... Val Loss: 0.133044\n",
      "Epoch: 1/1... Step: 7200... Loss: 0.119945... Val Loss: 0.133101\n",
      "Epoch: 1/1... Step: 7300... Loss: 0.050619... Val Loss: 0.133265\n",
      "Epoch: 1/1... Step: 7400... Loss: 0.054842... Val Loss: 0.132879\n",
      "Epoch: 1/1... Step: 7500... Loss: 0.024925... Val Loss: 0.132365\n",
      "Epoch: 1/1... Step: 7600... Loss: 0.212002... Val Loss: 0.132974\n",
      "Epoch: 1/1... Step: 7700... Loss: 0.133866... Val Loss: 0.133303\n",
      "Epoch: 1/1... Step: 7800... Loss: 0.086285... Val Loss: 0.133034\n",
      "Epoch: 1/1... Step: 7900... Loss: 0.138832... Val Loss: 0.134831\n",
      "Epoch: 1/1... Step: 8000... Loss: 0.166676... Val Loss: 0.130903\n",
      "Epoch: 1/1... Step: 8100... Loss: 0.111522... Val Loss: 0.133072\n",
      "Epoch: 1/1... Step: 8200... Loss: 0.143529... Val Loss: 0.131694\n",
      "Epoch: 1/1... Step: 8300... Loss: 0.159297... Val Loss: 0.132367\n",
      "Epoch: 1/1... Step: 8400... Loss: 0.076036... Val Loss: 0.132621\n",
      "Epoch: 1/1... Step: 8500... Loss: 0.062538... Val Loss: 0.133190\n",
      "Epoch: 1/1... Step: 8600... Loss: 0.035747... Val Loss: 0.130525\n",
      "Epoch: 1/1... Step: 8700... Loss: 0.142346... Val Loss: 0.131366\n",
      "Epoch: 1/1... Step: 8800... Loss: 0.125858... Val Loss: 0.131933\n",
      "Epoch: 1/1... Step: 8900... Loss: 0.184315... Val Loss: 0.132674\n",
      "Epoch: 1/1... Step: 9000... Loss: 0.089510... Val Loss: 0.131561\n",
      "Epoch: 1/1... Step: 9100... Loss: 0.047918... Val Loss: 0.131350\n",
      "Epoch: 1/1... Step: 9200... Loss: 0.051606... Val Loss: 0.129987\n",
      "Epoch: 1/1... Step: 9300... Loss: 0.195940... Val Loss: 0.133886\n",
      "Epoch: 1/1... Step: 9400... Loss: 0.045510... Val Loss: 0.132723\n",
      "Epoch: 1/1... Step: 9500... Loss: 0.115918... Val Loss: 0.131185\n",
      "Epoch: 1/1... Step: 9600... Loss: 0.138249... Val Loss: 0.133595\n",
      "Epoch: 1/1... Step: 9700... Loss: 0.356176... Val Loss: 0.130102\n",
      "Epoch: 1/1... Step: 9800... Loss: 0.096180... Val Loss: 0.134537\n",
      "Epoch: 1/1... Step: 9900... Loss: 0.064408... Val Loss: 0.129459\n",
      "Epoch: 1/1... Step: 10000... Loss: 0.144865... Val Loss: 0.129236\n",
      "Epoch: 1/1... Step: 10100... Loss: 0.165408... Val Loss: 0.129390\n",
      "Epoch: 1/1... Step: 10200... Loss: 0.143797... Val Loss: 0.129917\n",
      "Epoch: 1/1... Step: 10300... Loss: 0.044914... Val Loss: 0.131219\n",
      "Epoch: 1/1... Step: 10400... Loss: 0.154167... Val Loss: 0.128411\n",
      "Epoch: 1/1... Step: 10500... Loss: 0.232929... Val Loss: 0.131615\n",
      "Epoch: 1/1... Step: 10600... Loss: 0.131918... Val Loss: 0.128117\n",
      "Epoch: 1/1... Step: 10700... Loss: 0.199046... Val Loss: 0.128448\n",
      "Epoch: 1/1... Step: 10800... Loss: 0.135024... Val Loss: 0.130865\n",
      "Epoch: 1/1... Step: 10900... Loss: 0.041819... Val Loss: 0.131186\n",
      "Epoch: 1/1... Step: 11000... Loss: 0.069545... Val Loss: 0.129431\n",
      "Epoch: 1/1... Step: 11100... Loss: 0.025986... Val Loss: 0.128857\n",
      "Epoch: 1/1... Step: 11200... Loss: 0.093054... Val Loss: 0.131287\n",
      "Epoch: 1/1... Step: 11300... Loss: 0.152200... Val Loss: 0.128360\n",
      "Epoch: 1/1... Step: 11400... Loss: 0.091987... Val Loss: 0.128749\n",
      "Epoch: 1/1... Step: 11500... Loss: 0.109994... Val Loss: 0.128197\n",
      "Epoch: 1/1... Step: 11600... Loss: 0.106328... Val Loss: 0.128261\n",
      "Epoch: 1/1... Step: 11700... Loss: 0.316853... Val Loss: 0.129545\n",
      "Epoch: 1/1... Step: 11800... Loss: 0.066219... Val Loss: 0.132207\n",
      "Epoch: 1/1... Step: 11900... Loss: 0.116301... Val Loss: 0.128646\n",
      "Epoch: 1/1... Step: 12000... Loss: 0.145217... Val Loss: 0.127634\n",
      "Epoch: 1/1... Step: 12100... Loss: 0.330486... Val Loss: 0.127208\n",
      "Epoch: 1/1... Step: 12200... Loss: 0.168190... Val Loss: 0.126628\n",
      "Epoch: 1/1... Step: 12300... Loss: 0.141574... Val Loss: 0.127265\n",
      "Epoch: 1/1... Step: 12400... Loss: 0.064832... Val Loss: 0.128600\n",
      "Epoch: 1/1... Step: 12500... Loss: 0.033791... Val Loss: 0.127153\n",
      "Epoch: 1/1... Step: 12600... Loss: 0.039673... Val Loss: 0.126780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1... Step: 12700... Loss: 0.271732... Val Loss: 0.127527\n",
      "Epoch: 1/1... Step: 12800... Loss: 0.161472... Val Loss: 0.127624\n",
      "Epoch: 1/1... Step: 12900... Loss: 0.122112... Val Loss: 0.128823\n",
      "Epoch: 1/1... Step: 13000... Loss: 0.090110... Val Loss: 0.127764\n",
      "Epoch: 1/1... Step: 13100... Loss: 0.181880... Val Loss: 0.129444\n",
      "Epoch: 1/1... Step: 13200... Loss: 0.056729... Val Loss: 0.126862\n",
      "Epoch: 1/1... Step: 13300... Loss: 0.151670... Val Loss: 0.126507\n",
      "Epoch: 1/1... Step: 13400... Loss: 0.075217... Val Loss: 0.128032\n",
      "Epoch: 1/1... Step: 13500... Loss: 0.126853... Val Loss: 0.130052\n",
      "Epoch: 1/1... Step: 13600... Loss: 0.056019... Val Loss: 0.125949\n",
      "Epoch: 1/1... Step: 13700... Loss: 0.113785... Val Loss: 0.128121\n",
      "Epoch: 1/1... Step: 13800... Loss: 0.191027... Val Loss: 0.129054\n",
      "Epoch: 1/1... Step: 13900... Loss: 0.170780... Val Loss: 0.127327\n",
      "Epoch: 1/1... Step: 14000... Loss: 0.083526... Val Loss: 0.125631\n",
      "Epoch: 1/1... Step: 14100... Loss: 0.193275... Val Loss: 0.126956\n",
      "Epoch: 1/1... Step: 14200... Loss: 0.051914... Val Loss: 0.132242\n",
      "Epoch: 1/1... Step: 14300... Loss: 0.086490... Val Loss: 0.127279\n",
      "Epoch: 1/1... Step: 14400... Loss: 0.177698... Val Loss: 0.126398\n",
      "Epoch: 1/1... Step: 14500... Loss: 0.129140... Val Loss: 0.130309\n",
      "Epoch: 1/1... Step: 14600... Loss: 0.115474... Val Loss: 0.125706\n",
      "Epoch: 1/1... Step: 14700... Loss: 0.141631... Val Loss: 0.125451\n",
      "Epoch: 1/1... Step: 14800... Loss: 0.071698... Val Loss: 0.125489\n",
      "Epoch: 1/1... Step: 14900... Loss: 0.212661... Val Loss: 0.124958\n",
      "Epoch: 1/1... Step: 15000... Loss: 0.052004... Val Loss: 0.125822\n",
      "Epoch: 1/1... Step: 15100... Loss: 0.087340... Val Loss: 0.124394\n",
      "Epoch: 1/1... Step: 15200... Loss: 0.070763... Val Loss: 0.124557\n",
      "Epoch: 1/1... Step: 15300... Loss: 0.070560... Val Loss: 0.124095\n",
      "Epoch: 1/1... Step: 15400... Loss: 0.056532... Val Loss: 0.125750\n",
      "Epoch: 1/1... Step: 15500... Loss: 0.141882... Val Loss: 0.125635\n",
      "Epoch: 1/1... Step: 15600... Loss: 0.030260... Val Loss: 0.124960\n"
     ]
    }
   ],
   "source": [
    "# training params\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "# move model to GPU, if available\n",
    "if(train_on_gpu):\n",
    "    net.cuda()\n",
    "\n",
    "net.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        if(train_on_gpu):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        output = net(inputs)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "\n",
    "                if(train_on_gpu):\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                output = net(inputs)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the Model\n",
    "After running the above training cell, the trained model will be saved by name, `trained_rnn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_model(filename, decoder):\n",
    "    save_filename = os.path.splitext(os.path.basename(filename))[0] + '.pt'\n",
    "    torch.save(decoder, save_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type Attention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "# saving the trained model\n",
    "save_model('./save/trained_rnn', trained_rnn)\n",
    "print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Model\n",
    "We can load the trained model that have been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "def load_model(filename):\n",
    "    save_filename = os.path.splitext(os.path.basename(filename))[0] + '.pt'\n",
    "    return torch.load(save_filename, map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.GRU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Sigmoid' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "net = load_model('./save/trained_rnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5. Testing\n",
    "\n",
    "We'll see how our trained model performs on all of our defined test_data, above. We'll calculate the average loss and accuracy over the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.125\n",
      "Test accuracy: 0.952\n"
     ]
    }
   ],
   "source": [
    "# Get test data loss and accuracy\n",
    "\n",
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "\n",
    "net.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "\n",
    "    if(train_on_gpu):\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    \n",
    "    # get predicted outputs\n",
    "    output = net(inputs)\n",
    "    \n",
    "    # calculate loss\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "\n",
    "# avg test loss\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
